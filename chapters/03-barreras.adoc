[[barriers]]
== 3. La realidad del hardware moderno

image::jrmora/03-barreras.jpg[align="center"]


Los algoritmos de exclusión mutua anteriores son formalmente correctos, pero no funcionan en la mayoría de procesadores modernosfootnote:[No debería decepcionar, la intención era aprender los fundamentos básicos para entender la evolución y cómo hemos llegado a las construcciones actuales.]. Los fabricantes intentan maximizar la potencia de sus procesadores con todos los medios posibles: desde múltiples niveles de caché; _buffer_ de escrituras; segmentación y cola de instrucciones (_instruction pipeline_); al uso ya extendido de varios núcleosfootnote:[Una de las razones de la popularización de la programación concurrente –también de la confusión entre concurrencia y paralelismo–, desarrollar programas con varios hilos para poder ejecutarlos en paralelo en los diferentes núcleos.]. No es posible la programación concurrente en estos procesadores sin el soporte de instrucciones especiales; sin ellas no se podría ni asegurar que se cumplan las condiciones de la _máquina universal de Turing_.


Para mostrar el problema programé el algoritmo de Peterson y lo ejecuté de la misma forma que a los programas del capítulo anterior (<<counter_times>>):

[NOTE]
====
En <<hardware>> veremos cómo se puede solucionar más eficientemente con instrucciones de hardware.
====

----
$ time ./counter_peterson
Counter value: 9879533 Expected: 10000000
real    0m0.598s
user    0m1.189s
sys     0m0.000s
----

Además del incremento notable de tiempo de CPU –casi 70 veces más–, el resultado sigue siendo erróneo. No se cumple la exclusión mutua, se _pierden_ operaciones, como si no hubiese control de acceso.

Los procesadores modernos no garantizan por defecto que los procesos ejecuten las instrucciones en el mismo orden que aparecen en el programa. Es decir, no aseguran  _consistencia secuencial_ de acceso a memoriafootnote:[Una forma habitual de verificar si una arquitectura asegura dicha consistencia secuencial es ejecutar el <<counter_peterson_c, algoritmo de Peterson>>, funciona correctamente en la Raspberry Pi con procesador ARM6, por ejemplo.].

Las tres razones que pueden provocar violaciones a la consistencia secuencial son:

- Optimizaciones del compilador.
- Incoherencia de caché de RAM en multiprocesadores.
- Ejecución fuera de orden.


=== Optimizaciones del compilador
Los compiladores pueden optimizar el código de varias formas, desde cambiar el orden de ejecución hasta usar registros como almacenamientos temporales (_buffers_) antes de copiarlos a memoria RAM. Para evitar que el compilador cambie el orden de ejecución de lecturas y escrituras de variables compartidas, en Cfootnote:[Tiene una semántica similar en C++ y Java, en este último es para evitar que se mantengan copias no sincronizadas en objetos usados en diferentes hilos] se puede especificar que una variable es _volatile_, por ejemplo:

    volatile int counter = 0;

El código del algoritmo de Peterson fue compilado sin optimizaciones, aún con +volatile+ no funciona. En este caso la causa del fallo de exclusión mutua es otra más sutil.

=== Caché de RAM en multiprocesadores

Los accesos a memoria RAM pueden tomar cientos de ciclos de procesador. Para reducir estas diferencias de velocidad los procesadores usan una jerarquía de hasta tres niveles de memoria caché: _L1_, _L2_ y _L3_. El nivel L1 suele estar integrado en el chip de la CPU, L2 tiene mayor capacidad y menor velocidad de acceso. En los procesadores más modernos L1 y L2 están integrados en cada núcleo y L3 es compartido por los núcleos en un mismo chip.

Cada caché almacena un bloque o _línea_ de la memoria RAM, cada una de ellas puede almacenar temporalmente de 64 a 256 bytes consecutivos. Cuando el procesador accede a una posición de memoria copia toda la línea correspondiente, los siguientes accesos se hacen directamente a la caché sin necesidad de acceder a la RAM. Las líneas de caché modificadas  se _marcan_ como tal para luego ser volcadas a la memoria RAM.


****
Se  usan varios mecanismos de _asociación_ para traducir de una dirección de memoria física a la línea correspondiente de la caché. En _direct mapping_ la asociación entre segmentos de direcciones de memoria y sus líneas correspondientes están predeterminadas. En sistemas de _hashing_ y asociatividad con _memoria direccionable por contenido_, cada línea puede almacenar cualquier posición alineada de memoria RAM.
****

Las arquitecturas _SMP_ deben mantener coherentes las copias de la memoria caché en cada procesador. Cada arquitectura puede o no garantizar la _coherencia de caché_, la buena noticia es que la mayoría de sistemas _SMP_ la aseguran.

==== Coherencia de caché en multiprocesadores

En arquitecturas _SMP_ los procesadores están conectados por una compleja red de comunicación, el _front side buffer_. La arquitectura de la red depende del fabricante. Puede ser del tipo _bus_, donde los datos se transfieren por un bus compartido; o arquitecturas más sofisticadas que permiten comunicaciones punto a punto entre procesadores, como la _QuickPath_ de Intel.


[[quickpath]]
.Arquitectura QuickPath de Intelfootnote:[Imagen de _An Introduction to the Intel QuickPath Interconnect, January 2009_ http://www.intel.es/content/dam/doc/white-paper/quick-path-interconnect-introduction-paper.pdf]
image::intel-quickpath.png[align="center"]

Para mantener la consistencia entre las diferentes copias de caché se usan algoritmos como _MESI_ (por _Modified_, _Exclusive_, _Shared_ e _Invalid_) y derivadosfootnote:[Por ejemplo _MESIF_ en Intel, F por _forward_.].

.Protocolo _MESI_
****
Cada línea de caché está en uno de los cuatro estados, _modified_, _exclusive_, _shared_ o _invalid_. Cada caché _escucha_ permanentemente al bus (_snoop_) y cambia el estado de la línea dependiendo de las operaciónes y mensajes que recibe.

Cuando un procesador lee de la memoria y carga en caché el estado se marca como _exclusive_.

Si otro procesador necesita acceder a la misma línea se le envía una copia y se marca su estado como _shared_.

Si el procesador modifica una línea cuyo estado es _shared_ se la etiqueta como _modified_ para que sea posteriormente copiada a RAM. Se envía un mensaje para que los demás procesadores marquen su copia como _invalid_.

Si debe acceder a datos en una línea etiquetada _invalid_, envía un mensaje de multidifusión (_broadcast_) para que el que tenga una copia válida (en estado _exclusive_ o _modified_) le responda con el valor actualizado. Si ninguno la tiene accede a la memoria RAM para obtener la copia.
****

Los sistemas de caché en sistemas _SMP_ aseguran la consistencia de caché. La incosistencia de caché no es el responsable del mal funcionamiento del algoritmo de exclusión mutua.

****
Era importante introducir el tema de la coherencia de caché, tiene una enorme influencia en el rendimiento de programas concurrentes en sistemas _SMP_.
****

===== La sobrecarga del acceso a variables compartidas

La ejecución de procesos es menos eficiente si acceden a las mismas zonas de memoria. Cada modificación de las variables almacenadas en la misma línea –aunque sean direcciones diferentes– obliga al sistema de caché a enviar mensajes de multidifusión para que los demás invaliden sus copias. Lo que provoca que por cada acceso a la misma variable se envíen mensajes, y sus respectivas respuestas, para obtener el valor actualizado.

El siguiente programa (<<counter_local_c, código>>) es lógicamente equivalente al contador <<counter_c, original>>, pero la suma la hace sobre una variable local en cada hilo (i.e. no compartidas) y se incrementa la compartida solo al final del bucle.

[source,c]
----
// The global variable
int local_counter = 0;

for (i=0; i < max; i++) {
    local_counter += 1;
}

// Add to the shared variable
counter += local_counter;
----

El original accede y modifica la variable compartida en cada iteración, el contador local solo una única vez al final. Este último consume menos del 50% de tiempo de CPU porque no genera operaciones de sincronización del sistema de caché.

----
$ time ./counter
Counter value: 6356922 Expected: 10000000
real	0m0.036s
user	0m0.064s
sys     0m0.000s

$ time ./counter_local
Counter value: 10000000 Expected: 10000000
real	0m0.014s
user	0m0.024s
sys     0m0.000s
----

[[false_sharing]]
._False sharing_
****
Si se iterará frecuentemente (_spinning_) sobre variables compartidas, es mejor asegurarse de que no comparten la misma línea de caché. Las variables han de ser _distantes_ –por ejemplo, locales de cada hilo– para evitar el efecto conocido como _false sharing_ que obliga al intercambio de mensajes aunque sean variables diferentes.
****


=== Ejecución fuera de orden

El problema de los algoritmos de exclusión mutua es la ejecución fuera de orden (_out of order execution_) o _ejecución dinámica_. Los procesadores reordenan las instrucciones con el objetivo de ahorrar ciclos de CPU. Por ejemplo, porque ya tienen valores cargados en registros, o porque una instrucción posterior ya ha sido decodificada en el _pipeline_. Los procesadores no aseguran la consistencia secuencial con respecto al orden del programa, en cambio, usan mecanismos de _dependencias causales_ o _débiles_ (_weak dependencies_) de acceso a memoria.

La dependencia causal funciona de la siguiente manera, supongamos un programa con las siguientes instrucciones:

    a = x
    b = y
    c = a * 2

El procesador puede ejecutarlas en diferentes secuencias sin que afecte al resultado, por ejemplo:

    a = x
    c = a * 2
    b = y

o

    b = y
    a = x
    c = a * 2


El procesador detecta que la asignación a +c+ la puede hacer antes que +b+, o a la de +b+ antes que a +a+ porque no hay dependencias entre ellas. Funciona perfectamente en procesos aislados, pero si se trata de procesos concurrentes es incapaz de detectar las dependencias causales entre ellos. Tomemos el algoritmo correcto más sencillo, <<peterson, Peterson>>, cuya entrada a la sección crítica es:

[source,python]
----
states[0] = True
turn = 1
while states[1] and turn == 1:
    pass
----

El procesador no detecta que las variables son modificadas por diferentes procesos, no encuentra dependencias entre +states[0]+ y +states[1]+. Para el procesador son dos variables independientes en la secuencia. Es factible que las ejecute en el siguiente orden:

[source,python]
----
turn = 1
while states[1] and turn == 1:
    pass
states[0] = True

   ## BOOOM!!! ##
----

El procesador puede ejecutarfootnote:[En el ejemplo exagero, esas instrucciones son de alto nivel y que cada una de ellas son varias instrucciones de procesador, pero creo que la analogía es razonable y se entiende mejor.] la asignación a +states[0]+ después de la verificación del valor de +states[1]+, en la secuencia de instrucciones individuales no hay dependencia causal entre ambas. Por supuesto, este reordenamiento hace que el algoritmo de exclusión mutua falle. Se debe solicitar al procesador, explícitamente y _bajo demanda_, que respete el orden de acceso a memoria entre diferentes segmentos del programa. Esto se hace con las _barreras de memoria_.


=== Barreras de memoria

Para que el algoritmo funcione correctamente deben especificarse _barreras_ (_fences_ o _barriers_) para asegurar que ciertas instrucciones mantienen su orden respecto a otras. Una instrucción de _barrera general_ indica al procesador:

. Antes de continuar deben ejecutarse todas las operaciones de lectura y escritura que están antes la barrera.

. Ninguna operación de lectura o escritura posterior a la barrera debe ejecutarse antes de ésta.

Supongamos que deseamos que la asignación de +c+ sea siempre posterior a la asignación de +a+ y +b+, como no hay dependencias detectables por la CPU debemos insertar una barrera entre ellas:

    a = x
    b = y
    BARRIER()
    c = a * 2

Esto forzará a que ambas asignaciones y lecturas de +x+ e +y+ se ejecuten antes de la asignación a +c+, lo que solo permitirá la siguiente alternativa (además de la secuencia anterior):

    b = y
    a = x
    BARRIER()
    c = a * 2

Debemos hacer lo mismo para que el algoritmo de Peterson funcione correctamente, hay que  insertar una barrera entre la asignación de +states+ y +turn+ y el +while+ que verifica el turno y estado del otro proceso:

[source,python]
----
states[0] = True
turn = 1
BARRIER()
while states[1] and turn == 1:
    pass
----


==== Tipos de barreras
Hay diferentes tipos de barreras y varían entre arquitecturas. Las tres tradicionales son de _lectura_, _escritura_ y la _general_. Hay alternativas similares, como las _acquire_, _release_ y _sequential_, usadas en los macros de GCC compatibles con el modelo de memoria de Ansi C/C++ de 2011footnote:[Si estáis interesados en aprender más sobre ellas y cómo afectan al desarrollo del núcleo Linux, un buen enlace para comenzar <<Howells>>.] (<<Atomics_C11>>).

- Una barrera _acquire_ es de _sentido único_ (+ATOMIC_ACQUIRE+), garantiza que todas las operaciones de memoria posteriores a la barrera _parecerán_ haber ocurrido después, las anteriores pueden ejecutarse antes y fuera de orden.

- Una barrera _release_ (+ATOMIC_RELEASE+) es similar a la anterior pero en sentido contrario. Los resultados de las operaciones previas a la barrera ocurrirán antes de la misma. Las posteriores a la barrera podrían ocurrir antes de la misma.

- La barrera _sequential_ (o _completa_, o _general_, +ATOMIC_SEQ_CST+) tiene dos sentidos, las operaciones previas ocurrirán antes y las posteriores después.


==== Uso de barreras
Debido a la complejidad del diseño y fabricación, los procesadores con ejecución fuera de orden no se popularizaron hasta mediados de la década de 1990 (con la introducción del procesador Power1). Las diferencias entre arquitecturas hicieron que cada una incluyese diferentes tipos de barreras. Así pues, no existen instrucciones estándares ni construcciones sintácticas específicas en la mayoría de lenguajes de programación.

Afortunadamente, el problema está relativamentefootnote:[Sigue siendo un problema que no haya macros estándares para todos los compiladores.] solucionado por los _builtin macros_ de los compiladores, como los del compilador GCC (<<Atomics_C11>>). El compilador define macros que se tratan como funciones normales del programa, cuando genera el código inserta las instrucciones específicas de cada arquitectura. GCC tiene varios _macros atómicos_, algunos de ellos las analizaremos y usaremos en el siguiente capítulo, por ahora nos interesa el genérico `__atomic_thread_fence`.footnote:[Este macro es de las versiones más modernas de GCC, en las antiguas versiones era `__sync_synchronize`.]

Hay que insertar la barrera en el sitio correcto, en el caso del algoritmo de Peterson ya lo sabemos (<<counter_peterson_c, código completo en C>>):

[source,c]
----
void lock(int i) {
    int j =  (i + 1) % 2;

    states[i] = 1;
    turn = j;
    __atomic_thread_fence();
    while (states[j] && turn == j);
}
----

Ahora la ejecución sí es correcta y produce el resultado esperado:

----
$ time ./counter_peterson
Counter value: 10000000 Expected: 10000000
real    0m0.616s
user    0m1.230s
sys     0m0.000s
----

En el algoritmo de Peterson la solución con barreras es sencilla, pero las soluciones se hacen más complejas y nada intuitivas en algoritmos más sofisticados. Por ejemplo, el algoritmo de la panadería (<<counter_peterson_c, código en C>>) y el rápido de Lamport (<<counter_fast, código en C>>) necesitan tres barreras en sitios diferentes.


.Instrucciones de barreras por arquitectura
****
- Intel 64 bits: +mfence+

- Intel 32 bits: +lock orl+

- ARMv6 de 32 bits (Raspberry Pi 1): +mcr  p15, 0, r0, c7, c10, 5+

- ARMv7 y posteriores: +dmb+
****

=== Recapitulación

En este capítulo hemos visto los problemas ocasionados por la ejecución fuera de orden de los procesadores modernos. Las barreras tienen un coste elevado –varios cientos de ciclos de CPU–, que se suma a la presión introducida al sistema de caché. Desde el punto de vista del programador, la mayor dificultad es saber exactamente dónde hay que insertar el mínimo número de barreras.

La programación con barreras explícitas no es práctica, tiende a producir errores. Hay que probarlas en diferentes arquitecturas y requieren de mucha experiencia. Los académicos  consideran que es un error permitir la ejecución fuera de orden, pero es el precio a pagar por procesadores más rápidos.

En cualquier caso, no tiene sentido programar mecanismos de sincronización como los vistos sin ayuda de primitivas de hardware que faciliten la programación. Las analizamos en el siguiente capítulo; no solo sirven para solucionar la exclusión mutua, también otros de sincronización y consenso.
